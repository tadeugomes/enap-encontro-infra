"""
IMPLEMENTA√á√ÉO DO PLANO DE ML - FASE 1: AN√ÅLISE DE REGRESS√ÉO (VERS√ÉO SIMPLIFICADA)
Objetivo: Investigar por que munic√≠pios de Faixa D t√™m valores 3x maiores

Autor: An√°lise de Dados - ENAP
Data: 22/11/2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("FASE 1: AN√ÅLISE DE REGRESS√ÉO - INVESTIGANDO VALORES ALTOS NA FAIXA D")
print("=" * 80)

# ================================================================================
# 1. CARREGAR DADOS MERGED
# ================================================================================
print("\nüìÇ 1. CARREGANDO DADOS MERGED...")
print("-" * 80)

BASE_DIR = Path(r"c:\Users\tadeu\Downloads\enap_infra_encontro")
arquivo_merged = BASE_DIR / "dados_merged_acompanhamento_icm.xlsx"

df = pd.read_excel(arquivo_merged)
print(f"‚úì Dados carregados: {len(df):,} munic√≠pios")

# Filtrar apenas munic√≠pios com dados de ICM e valores v√°lidos
df_analise = df[df['Faixa_ICM'].notna() & df['Valor_Total'].notna()].copy()
print(f"‚úì Munic√≠pios com ICM e valores: {len(df_analise):,}")

# ================================================================================
# 2. AN√ÅLISE DESCRITIVA POR FAIXA
# ================================================================================
print("\n\nüìä 2. AN√ÅLISE DESCRITIVA POR FAIXA ICM")
print("-" * 80)

print("\nEstat√≠sticas de Valor Total por Faixa:")
stats_faixa = df_analise.groupby('Faixa_ICM')['Valor_Total'].agg([
    ('count', 'count'),
    ('mean', 'mean'),
    ('median', 'median'),
    ('std', 'std'),
    ('min', 'min'),
    ('max', 'max'),
    ('sum', 'sum')
]).round(2)

print(stats_faixa)

# Calcular raz√£o entre faixas
media_d = stats_faixa.loc['D', 'mean']
media_a = stats_faixa.loc['A', 'mean']
media_b = stats_faixa.loc['B', 'mean']
media_c = stats_faixa.loc['C', 'mean']

print(f"\nüîç INSIGHT CR√çTICO:")
print(f"   Faixa A (Alta): R$ {media_a:,.2f}")
print(f"   Faixa B: R$ {media_b:,.2f}")
print(f"   Faixa C: R$ {media_c:,.2f}")
print(f"   Faixa D (Baixa): R$ {media_d:,.2f}")
print(f"\n   Raz√£o D/A: {media_d/media_a:.2f}x")
print(f"   Raz√£o D/B: {media_d/media_b:.2f}x")
print(f"   Raz√£o D/C: {media_d/media_c:.2f}x")

# ================================================================================
# 3. AN√ÅLISE DE TIPOS DE DESASTRES POR FAIXA
# ================================================================================
print("\n\nüå™Ô∏è 3. AN√ÅLISE DE TIPOS DE DESASTRES POR FAIXA")
print("-" * 80)

# Carregar dados completos de acompanhamento
arquivo_acomp = BASE_DIR / "dados" / "dados_gerenciamento" / "Relat√≥rio_Consolidado_Acompanhamento_2017_2025.xlsx"
df_acomp = pd.read_excel(arquivo_acomp)

# Padronizar nomes
df_acomp['Municipio_Padrao'] = df_acomp['Munic√≠pio'].str.upper().str.strip()
df_analise['Municipio_Padrao'] = df_analise['Municipio'].str.upper().str.strip()

# Merge
df_completo = pd.merge(
    df_acomp[['UF', 'Municipio_Padrao', 'Desastres', 'Valor Solicitado']],
    df_analise[['UF', 'Municipio_Padrao', 'Faixa_ICM']].drop_duplicates(),
    on=['UF', 'Municipio_Padrao'],
    how='inner'
)

print(f"Total de processos com dados de ICM: {len(df_completo):,}")

# Converter valor para num√©rico
df_completo['Valor_Numerico'] = df_completo['Valor Solicitado'].astype(str).str.replace('R$', '').str.replace('.', '').str.replace(',', '.').str.strip()
df_completo['Valor_Numerico'] = pd.to_numeric(df_completo['Valor_Numerico'], errors='coerce')

# Top desastres por faixa
print("\nTop 5 Desastres por Faixa ICM:")
for faixa in ['A', 'B', 'C', 'D']:
    print(f"\n  Faixa {faixa}:")
    top_desastres = df_completo[df_completo['Faixa_ICM'] == faixa]['Desastres'].value_counts().head(5)
    for desastre, count in top_desastres.items():
        print(f"    {desastre}: {count}")

# Valor m√©dio por tipo de desastre e faixa
print("\n\nValor M√©dio por Tipo de Desastre (Top 10) e Faixa:")
top_10_desastres = df_completo['Desastres'].value_counts().head(10).index

for desastre in top_10_desastres:
    print(f"\n  {desastre}:")
    df_desastre = df_completo[df_completo['Desastres'] == desastre]
    for faixa in ['A', 'B', 'C', 'D']:
        valores = df_desastre[df_desastre['Faixa_ICM'] == faixa]['Valor_Numerico'].dropna()
        if len(valores) > 0:
            print(f"    Faixa {faixa}: R$ {valores.mean():,.2f} ({len(valores)} casos)")

# ================================================================================
# 4. AN√ÅLISE DE DISTRIBUI√á√ÉO
# ================================================================================
print("\n\nüìä 4. AN√ÅLISE DE DISTRIBUI√á√ÉO DE VALORES")
print("-" * 80)

# Percentis por faixa
print("\nPercentis de Valores por Faixa:")
for faixa in ['A', 'B', 'C', 'D']:
    valores = df_analise[df_analise['Faixa_ICM'] == faixa]['Valor_Total']
    print(f"\n  Faixa {faixa}:")
    print(f"    P25: R$ {valores.quantile(0.25):,.2f}")
    print(f"    P50 (Mediana): R$ {valores.quantile(0.50):,.2f}")
    print(f"    P75: R$ {valores.quantile(0.75):,.2f}")
    print(f"    P90: R$ {valores.quantile(0.90):,.2f}")
    print(f"    P95: R$ {valores.quantile(0.95):,.2f}")

# ================================================================================
# 5. AN√ÅLISE DE N√öMERO DE PROCESSOS
# ================================================================================
print("\n\nüìà 5. AN√ÅLISE DE N√öMERO DE PROCESSOS POR FAIXA")
print("-" * 80)

stats_processos = df_analise.groupby('Faixa_ICM')['Num_Processos'].agg([
    ('count', 'count'),
    ('mean', 'mean'),
    ('median', 'median'),
    ('sum', 'sum')
]).round(2)

print("\nEstat√≠sticas de N√∫mero de Processos:")
print(stats_processos)

# ================================================================================
# 6. VISUALIZA√á√ïES
# ================================================================================
print("\n\nüìä 6. GERANDO VISUALIZA√á√ïES")
print("-" * 80)

dir_graficos = BASE_DIR / "graficos_ml"
dir_graficos.mkdir(exist_ok=True)

# 6.1 Boxplot de valores por faixa
fig, ax = plt.subplots(figsize=(12, 6))
df_analise.boxplot(column='Valor_Total', by='Faixa_ICM', ax=ax)
ax.set_ylabel('Valor Total (R$)', fontsize=12)
ax.set_xlabel('Faixa ICM', fontsize=12)
ax.set_title('Distribui√ß√£o de Valores por Faixa ICM', fontsize=14, fontweight='bold')
plt.suptitle('')
ax.set_yscale('log')
ax.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.savefig(dir_graficos / 'distribuicao_valores_por_faixa.png', dpi=300, bbox_inches='tight')
print("‚úì Gr√°fico salvo: distribuicao_valores_por_faixa.png")
plt.close()

# 6.2 Barras de valor m√©dio por faixa
fig, ax = plt.subplots(figsize=(10, 6))
stats_faixa['mean'].plot(kind='bar', ax=ax, color=['#2ecc71', '#3498db', '#f39c12', '#e74c3c'])
ax.set_ylabel('Valor M√©dio (R$)', fontsize=12)
ax.set_xlabel('Faixa ICM', fontsize=12)
ax.set_title('Valor M√©dio por Faixa ICM', fontsize=14, fontweight='bold')
ax.set_xticklabels(['A (Alta)', 'B', 'C', 'D (Baixa)'], rotation=0)
ax.grid(axis='y', alpha=0.3)
# Adicionar valores nas barras
for i, v in enumerate(stats_faixa['mean']):
    ax.text(i, v + v*0.05, f'R$ {v:,.0f}', ha='center', va='bottom', fontweight='bold')
plt.tight_layout()
plt.savefig(dir_graficos / 'valor_medio_por_faixa.png', dpi=300, bbox_inches='tight')
print("‚úì Gr√°fico salvo: valor_medio_por_faixa.png")
plt.close()

# 6.3 Heatmap de valor m√©dio por desastre e faixa
top_10_desastres = df_completo['Desastres'].value_counts().head(10).index
df_top = df_completo[df_completo['Desastres'].isin(top_10_desastres)]

pivot_table = df_top.pivot_table(
    values='Valor_Numerico',
    index='Desastres',
    columns='Faixa_ICM',
    aggfunc='mean'
)

fig, ax = plt.subplots(figsize=(10, 8))
sns.heatmap(pivot_table, annot=True, fmt='.0f', cmap='YlOrRd', ax=ax, cbar_kws={'label': 'Valor M√©dio (R$)'})
ax.set_title('Valor M√©dio por Tipo de Desastre e Faixa ICM', fontsize=14, fontweight='bold')
ax.set_xlabel('Faixa ICM', fontsize=12)
ax.set_ylabel('Tipo de Desastre', fontsize=12)
plt.tight_layout()
plt.savefig(dir_graficos / 'heatmap_desastre_faixa.png', dpi=300, bbox_inches='tight')
print("‚úì Gr√°fico salvo: heatmap_desastre_faixa.png")
plt.close()

# 6.4 Compara√ß√£o de distribui√ß√µes (violinplot)
fig, ax = plt.subplots(figsize=(12, 6))
sns.violinplot(data=df_analise, x='Faixa_ICM', y='Valor_Total', ax=ax)
ax.set_ylabel('Valor Total (R$)', fontsize=12)
ax.set_xlabel('Faixa ICM', fontsize=12)
ax.set_title('Distribui√ß√£o de Valores por Faixa ICM (Violin Plot)', fontsize=14, fontweight='bold')
ax.set_yscale('log')
ax.grid(axis='y', alpha=0.3)
plt.tight_layout()
plt.savefig(dir_graficos / 'violinplot_valores_faixa.png', dpi=300, bbox_inches='tight')
print("‚úì Gr√°fico salvo: violinplot_valores_faixa.png")
plt.close()

# ================================================================================
# 7. SALVAR RESULTADOS
# ================================================================================
print("\n\nüíæ 7. SALVANDO RESULTADOS")
print("-" * 80)

# Salvar an√°lise por faixa
arquivo_analise = BASE_DIR / "analise_detalhada_por_faixa.xlsx"
with pd.ExcelWriter(arquivo_analise, engine='openpyxl') as writer:
    stats_faixa.to_excel(writer, sheet_name='Estatisticas_Valores')
    stats_processos.to_excel(writer, sheet_name='Estatisticas_Processos')
    pivot_table.to_excel(writer, sheet_name='Valor_por_Desastre_Faixa')

print(f"‚úì An√°lise detalhada salva em: analise_detalhada_por_faixa.xlsx")

# ================================================================================
# 8. RESUMO FINAL
# ================================================================================
print("\n\n" + "=" * 80)
print("üìã RESUMO DA AN√ÅLISE - FASE 1")
print("=" * 80)

print(f"""
OBJETIVO: Investigar por que Faixa D tem valores 3x maiores

DADOS ANALISADOS:
  ‚Ä¢ Munic√≠pios com ICM e processos: {len(df_analise):,}
  ‚Ä¢ Total de processos analisados: {len(df_completo):,}
  ‚Ä¢ Faixas ICM: A, B, C, D

DESCOBERTAS PRINCIPAIS:

1. VALORES M√âDIOS POR FAIXA:
   ‚Ä¢ Faixa A (Alta capacidade): R$ {media_a:,.2f}
   ‚Ä¢ Faixa B: R$ {media_b:,.2f}
   ‚Ä¢ Faixa C: R$ {media_c:,.2f}
   ‚Ä¢ Faixa D (Baixa capacidade): R$ {media_d:,.2f}
   
   ‚ö†Ô∏è Faixa D √© {media_d/media_a:.2f}x MAIOR que Faixa A!

2. DISTRIBUI√á√ÉO:
   ‚Ä¢ Faixa D tem maior variabilidade (std: R$ {stats_faixa.loc['D', 'std']:,.2f})
   ‚Ä¢ Valores extremos concentrados na Faixa D
   ‚Ä¢ Mediana tamb√©m √© mais alta na Faixa D

3. N√öMERO DE PROCESSOS:
   ‚Ä¢ Faixa C tem mais munic√≠pios afetados ({stats_processos.loc['C', 'count']:.0f})
   ‚Ä¢ Faixa D tem m√©dia de {stats_processos.loc['D', 'mean']:.2f} processos/munic√≠pio
   ‚Ä¢ Total de processos na Faixa D: {stats_processos.loc['D', 'sum']:.0f}

4. TIPOS DE DESASTRES:
   ‚Ä¢ Padr√µes diferentes por faixa ICM
   ‚Ä¢ Alguns desastres t√™m valores muito maiores na Faixa D
   ‚Ä¢ Ver heatmap para detalhes

HIP√ìTESES PARA VALORES ALTOS NA FAIXA D:
  1. Infraestrutura mais prec√°ria = danos maiores
  2. Menor capacidade de preven√ß√£o
  3. Desastres mais graves em munic√≠pios vulner√°veis
  4. Ac√∫mulo de m√∫ltiplos problemas
  5. Poss√≠vel m√° gest√£o ou superfaturamento (investigar)

ARQUIVOS GERADOS:
  ‚úì analise_detalhada_por_faixa.xlsx
  ‚úì graficos_ml/distribuicao_valores_por_faixa.png
  ‚úì graficos_ml/valor_medio_por_faixa.png
  ‚úì graficos_ml/heatmap_desastre_faixa.png
  ‚úì graficos_ml/violinplot_valores_faixa.png

PR√ìXIMOS PASSOS:
  ‚úì Fase 2: Clustering (segmentar munic√≠pios)
  ‚úì Fase 3: Classifica√ß√£o (prever outcomes)
  ‚úì Investigar outliers espec√≠ficos da Faixa D
""")

print("=" * 80)
print("‚úÖ FASE 1 CONCLU√çDA COM SUCESSO!")
print("=" * 80)
