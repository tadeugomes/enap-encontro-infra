"""
IMPLEMENTA√á√ÉO DO PLANO DE ML - FASE 2: CLUSTERIZA√á√ÉO (SEGMENTA√á√ÉO DE MUNIC√çPIOS)
Objetivo: Agrupar munic√≠pios por comportamento real de solicita√ß√µes, independente da Faixa ICM.

Autor: An√°lise de Dados - ENAP
Data: 23/11/2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, RobustScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score
from pathlib import Path
import warnings

warnings.filterwarnings('ignore')

# Configura√ß√£o de estilo
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("viridis")

print("=" * 80)
print("FASE 2: CLUSTERIZA√á√ÉO - SEGMENTA√á√ÉO DE MUNIC√çPIOS")
print("=" * 80)

# ================================================================================
# 1. CARREGAR DADOS
# ================================================================================
print("\nüìÇ 1. CARREGANDO DADOS...")
BASE_DIR = Path(r"c:\Users\tadeu\Downloads\enap_infra_encontro")
arquivo_merged = BASE_DIR / "dados" / "dados_processados" / "dados_merged_acompanhamento_icm.xlsx"

# Tentar carregar do local padr√£o ou do local organizado
if not arquivo_merged.exists():
    arquivo_merged = BASE_DIR / "02_dados_processados" / "dados_merged_acompanhamento_icm.xlsx"

df = pd.read_excel(arquivo_merged)
print(f"‚úì Dados carregados: {len(df):,} munic√≠pios")

# Filtrar apenas munic√≠pios com dados num√©ricos v√°lidos
df_cluster = df.dropna(subset=['Num_Processos', 'Valor_Total']).copy()
print(f"‚úì Munic√≠pios iniciais: {len(df_cluster):,}")

# Garantir que n√£o h√° valores negativos para o Log
df_cluster['Valor_Total'] = df_cluster['Valor_Total'].clip(lower=0)
df_cluster['Valor_Medio'] = df_cluster['Valor_Medio'].clip(lower=0)

# Preencher NaNs em Valor_Medio com 0 (caso exista)
df_cluster['Valor_Medio'] = df_cluster['Valor_Medio'].fillna(0)

print("\n‚öôÔ∏è 2. PREPARANDO FEATURES...")

# Criar features derivadas
# Log do valor total (para lidar com a assimetria/outliers)
df_cluster['Log_Valor_Total'] = np.log1p(df_cluster['Valor_Total'])
df_cluster['Log_Valor_Medio'] = np.log1p(df_cluster['Valor_Medio'])

# Selecionar features para o modelo
features_cols = ['Num_Processos', 'Log_Valor_Total', 'Log_Valor_Medio']
X = df_cluster[features_cols]

# Verificar e limpar NaNs/Infs resultantes
X = X.replace([np.inf, -np.inf], np.nan)
X = X.fillna(0) # Preencher qualquer NaN restante com 0

# Sincronizar df_cluster com X limpo (caso tenhamos removido linhas, mas aqui preenchemos)
# Se tiv√©ssemos removido linhas, precisar√≠amos fazer: df_cluster = df_cluster.loc[X.index]

print("Features selecionadas:")
for col in features_cols:
    print(f"  - {col} (Min: {X[col].min():.2f}, Max: {X[col].max():.2f})")

# Escalonamento (RobustScaler √© melhor com outliers)
scaler = RobustScaler()
X_scaled = scaler.fit_transform(X)

# ================================================================================
# 3. DETERMINAR N√öMERO IDEAL DE CLUSTERS (ELBOW METHOD)
# ================================================================================
print("\nüîç 3. DEFININDO N√öMERO DE CLUSTERS...")

inertia = []
silhouette_scores = []
K_range = range(2, 8)

for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(X_scaled)
    inertia.append(kmeans.inertia_)
    silhouette_scores.append(silhouette_score(X_scaled, kmeans.labels_))

# Decis√£o autom√°tica: Melhor Silhouette Score
best_k = K_range[np.argmax(silhouette_scores)]
print(f"‚úì Melhor K sugerido (Silhouette): {best_k}")

# Vamos for√ßar 4 clusters para comparar com as 4 faixas do ICM, 
# a menos que o score seja muito ruim.
n_clusters = 4
print(f"‚úì Definido K = {n_clusters} para comparabilidade com Faixas ICM")

# ================================================================================
# 4. APLICAR K-MEANS
# ================================================================================
print(f"\nü§ñ 4. APLICANDO K-MEANS (K={n_clusters})...")

kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)
df_cluster['Cluster'] = kmeans.fit_predict(X_scaled)

# Reordenar clusters para que 0 seja "Menor Impacto" e 3 seja "Maior Impacto"
# Baseado na m√©dia de Valor Total
cluster_means = df_cluster.groupby('Cluster')['Valor_Total'].mean().sort_values()
mapping = {old: new for new, old in enumerate(cluster_means.index)}
df_cluster['Cluster_Ordenado'] = df_cluster['Cluster'].map(mapping)

# Nomes descritivos para os clusters (baseado na an√°lise posterior, mas definindo aqui)
# Ser√° ajustado dinamicamente
print("‚úì Clusteriza√ß√£o conclu√≠da")

# ================================================================================
# 5. AN√ÅLISE DOS CLUSTERS
# ================================================================================
print("\nüìä 5. ANALISANDO RESULTADOS...")

# Estat√≠sticas por Cluster
stats_cluster = df_cluster.groupby('Cluster_Ordenado').agg({
    'Num_Processos': 'mean',
    'Valor_Total': 'mean',
    'Valor_Medio': 'mean',
    'Municipio': 'count'
}).round(2)

stats_cluster.columns = ['M√©dia Processos', 'M√©dia Valor Total', 'M√©dia Valor Processo', 'Qtd Munic√≠pios']
print("\nPerfil dos Clusters:")
print(stats_cluster)

# Cruzamento: Cluster vs Faixa ICM
crosstab = pd.crosstab(df_cluster['Cluster_Ordenado'], df_cluster['Faixa_ICM'])
print("\nMatriz de Confus√£o (Cluster vs Faixa ICM):")
print(crosstab)

# ================================================================================
# 6. VISUALIZA√á√ÉO
# ================================================================================
print("\nüé® 6. GERANDO VISUALIZA√á√ïES...")

dir_output = BASE_DIR / "04_visualizacoes" / "fase2_clustering"
dir_output.mkdir(parents=True, exist_ok=True)

# 6.1 Scatter Plot (PCA 2D)
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)
df_cluster['PCA1'] = X_pca[:, 0]
df_cluster['PCA2'] = X_pca[:, 1]

plt.figure(figsize=(10, 8))
sns.scatterplot(data=df_cluster, x='PCA1', y='PCA2', hue='Cluster_Ordenado', palette='viridis', s=60, alpha=0.7)
plt.title('Mapa de Clusters dos Munic√≠pios (PCA)', fontsize=14, fontweight='bold')
plt.xlabel('Componente Principal 1 (Intensidade Financeira)')
plt.ylabel('Componente Principal 2 (Frequ√™ncia)')
plt.legend(title='Cluster')
plt.tight_layout()
plt.savefig(dir_output / 'mapa_clusters_pca.png', dpi=300)
print("‚úì Gr√°fico salvo: mapa_clusters_pca.png")

# 6.2 Boxplot Valor Total por Cluster
plt.figure(figsize=(10, 6))
sns.boxplot(data=df_cluster, x='Cluster_Ordenado', y='Log_Valor_Total', palette='viridis')
plt.title('Distribui√ß√£o de Valores por Cluster (Escala Log)', fontsize=14)
plt.ylabel('Log(Valor Total)')
plt.xlabel('Cluster')
plt.tight_layout()
plt.savefig(dir_output / 'boxplot_valor_cluster.png', dpi=300)
print("‚úì Gr√°fico salvo: boxplot_valor_cluster.png")

# 6.3 Heatmap Cluster vs Faixa ICM
plt.figure(figsize=(10, 6))
sns.heatmap(crosstab, annot=True, fmt='d', cmap='Blues')
plt.title('Cluster Comportamental vs Faixa ICM Oficial', fontsize=14)
plt.ylabel('Cluster (Comportamento Real)')
plt.xlabel('Faixa ICM (Capacidade Te√≥rica)')
plt.tight_layout()
plt.savefig(dir_output / 'heatmap_cluster_vs_icm.png', dpi=300)
print("‚úì Gr√°fico salvo: heatmap_cluster_vs_icm.png")

# ================================================================================
# 7. SALVAR RESULTADOS
# ================================================================================
print("\nüíæ 7. SALVANDO RESULTADOS...")

dir_analises = BASE_DIR / "03_analises" / "fase2_clustering"
dir_analises.mkdir(parents=True, exist_ok=True)

# Salvar dataset com clusters
arquivo_final = BASE_DIR / "02_dados_processados" / "dados_municipios_clusterizados.xlsx"
df_cluster.to_excel(arquivo_final, index=False)
print(f"‚úì Dados clusterizados salvos em: {arquivo_final.name}")

# Salvar relat√≥rio de estat√≠sticas
arquivo_stats = dir_analises / "perfil_clusters.xlsx"
with pd.ExcelWriter(arquivo_stats) as writer:
    stats_cluster.to_excel(writer, sheet_name='Perfil_Clusters')
    crosstab.to_excel(writer, sheet_name='Cluster_vs_ICM')

print(f"‚úì Relat√≥rio salvo em: {arquivo_stats.name}")

print("\n" + "=" * 80)
print("‚úÖ FASE 2 (CLUSTERIZA√á√ÉO) CONCLU√çDA!")
print("=" * 80)
