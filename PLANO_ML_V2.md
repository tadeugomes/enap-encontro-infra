# üß† PLANO ESTRAT√âGICO DE MACHINE LEARNING (V2.0)

**Status**: Atualizado P√≥s-Limpeza de Dados (Crit√©rio de Risco)  
**Data**: 22/11/2025  
**Base de Dados**: `ICM_Consolidado_LIMPO_V2.xlsx` (5.444 munic√≠pios)

---

## üéØ OBJETIVO CENTRAL
Utilizar intelig√™ncia artificial para **otimizar a aloca√ß√£o de recursos** e **mitigar riscos** na reconstru√ß√£o de infraestrutura, focando na disparidade identificada entre a capacidade institucional (ICM) e os valores solicitados.

---

## üîÑ CICLO DE VIDA DO PROJETO

### ‚úÖ FASE 1: An√°lise de Regress√£o Explorat√≥ria (CONCLU√çDA)
*Investiga√ß√£o inicial das disparidades de valores.*

- **Conquista**: Identifica√ß√£o de que a **Faixa D** possui valores m√©dios **2,94x superiores** √† Faixa A.
- **Entregas**:
  - Script `ml_fase1_regressao.py`.
  - Relat√≥rio `analise_detalhada_por_faixa.xlsx`.
  - Visualiza√ß√µes de distribui√ß√£o e boxplots.
- **Status**: ‚úÖ Conclu√≠do (Base atualizada com Crit√©rio de Benef√≠cio).

### üöÄ FASE 2: Clusteriza√ß√£o e Segmenta√ß√£o (PR√ìXIMA)
*Entender grupos de comportamento al√©m da Faixa ICM.*

- **Objetivo**: Agrupar munic√≠pios n√£o apenas pelo ICM oficial, mas pelo **comportamento real** de solicita√ß√µes.
- **Algoritmo**: **K-Means** (para grupos) e **Isolation Forest** (para anomalias dentro dos grupos).
- **Hip√≥tese**: Existem munic√≠pios classificados como "Faixa B" que se comportam como "Faixa D"?
- **Features**:
  - Valor total solicitado acumulado.
  - Taxa de aprova√ß√£o hist√≥rica.
  - Diversidade de tipos de desastres.
- **Entrega**: Mapa de Clusters (ex: "Munic√≠pios de Alta Demanda e Baixa Efici√™ncia").

### üîÆ FASE 3: Classifica√ß√£o (Predi√ß√£o de Risco)
*Prever o resultado antes da an√°lise humana.*

- **Objetivo**: Estimar a probabilidade de um processo ser **INDEFERIDO** ou ficar **SOBRESTADO**.
- **Algoritmo**: **XGBoost Classifier** ou **Random Forest**.
- **Target**: Status (Bin√°rio: 1=Aprovado/Transferido, 0=Outros).
- **Aplica√ß√£o**: Score de Viabilidade para novos processos.

### üìâ FASE 4: Regress√£o Preditiva (Estimativa de Valor Justo)
*Modelagem avan√ßada para prever valores.*

- **Objetivo**: Criar um modelo de refer√™ncia para o "Custo Esperado" de um desastre.
- **Algoritmo**: **Quantile Regression**.
- **Entrega**: Estimativa de range de valor aceit√°vel para cada tipo de desastre.

---

## üõ†Ô∏è PIPELINE T√âCNICA

### 1. Engenharia de Features (Feature Engineering)
Precisamos criar novas vari√°veis para enriquecer os modelos:
- `log_valor`: Logaritmo do valor (para reduzir impacto de outliers extremos).
- `taxa_aprovacao_mun`: % de processos aprovados do munic√≠pio nos √∫ltimos anos.
- `dias_analise`: Tempo m√©dio de an√°lise (se dispon√≠vel futuramente).
- `sazonalidade`: M√™s do desastre (chuvas vs seca).

### 2. Tratamento de Dados
- **Normaliza√ß√£o**: StandardScaler para algoritmos de dist√¢ncia (K-Means).
- **Encoding**: Transformar `Faixa ICM` e `Tipo de Desastre` em n√∫meros.
- **Imputa√ß√£o**: Tratar nulos (embora a limpeza V2 j√° tenha resolvido a maioria).

### 3. Valida√ß√£o
- **Cross-Validation**: K-Fold (5 folds) para garantir robustez.
- **M√©tricas**:
  - Anomalias: Precision@K (quantos dos top K alertas s√£o reais problemas).
  - Classifica√ß√£o: ROC-AUC e F1-Score (balancear precis√£o e recall).
  - Clusteriza√ß√£o: Silhouette Score.

---

## üìÖ CRONOGRAMA SUGERIDO

1. **Semana 1 (Atual)**: 
   - Implementar **Isolation Forest** (Fase 1).
   - Comparar anomalias autom√°ticas com os outliers manuais j√° identificados.
   
2. **Semana 2**:
   - Engenharia de Features (criar vari√°veis agregadas).
   - Implementar **K-Means** (Fase 2) para segmenta√ß√£o.

3. **Semana 3**:
   - Treinar modelo de **Classifica√ß√£o de Aprova√ß√£o** (Fase 3).
   - Gerar relat√≥rio final de intelig√™ncia.

---

## ‚ö†Ô∏è PONTOS DE ATEN√á√ÉO

- **Vi√©s da Faixa D**: Como assumimos a pior faixa na limpeza, o modelo pode "aprender" que Faixa D √© inerentemente mais problem√°tica. Devemos monitorar isso.
- **Volume de Dados**: Temos ~6.000 processos. √â um dataset pequeno para Deep Learning, mas suficiente para Tree-based models (XGBoost).

---

**Autor**: Agente de IA (Antigravity)  
**Aprova√ß√£o**: ENAP / Infra Encontro
